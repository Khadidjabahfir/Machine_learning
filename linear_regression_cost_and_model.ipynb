{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca0fd30-27ea-40bf-b7c5-9bcbf74dbbc3",
   "metadata": {},
   "source": [
    "# linear regression cost and model \n",
    "in this lab we will try to give an insight on linear regression by explaining briefly some concept and implementing both the cost and model. \n",
    "## jupyter notebook structure \n",
    "each segment will a briefly explanation followed by an implementation and test cases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c685f3c-6100-438b-beff-9643900a9d18",
   "metadata": {},
   "source": [
    "# Model \n",
    "a linear regression is characterized by fitting a straight line that allows to predict values from out the training set. The straight line is of a linear function as follows $f(x) = wx+b$ where x is a vector of feature , w is a vectore of parameter and b is a parameter represented as an integer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1644df3a-db8a-4360-8fda-07dc3ea4bde1",
   "metadata": {},
   "source": [
    "#### non vectorization implementation : \n",
    "when we talk about a non vectorization problem we are referring to the multiplication of w and x. a way to do it is loop over w and x (they must have the same dimension for sure). the result of the multiplication is an integer that we will add to it the b. \n",
    "(1,2,3) * (4,5,6 ) = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f961e-9344-4357-af60-a7b5d6df8216",
   "metadata": {},
   "source": [
    "#### non vectorization implementation : \n",
    "when we talk about a non vectorization problem we are referring to the multiplication of w and x. a way to do it is loop over w and x (they must have the same dimension for sure). the result of the multiplication is an integer that we will add to it the b. \n",
    "(1,2,3) * (4,5,6 ) = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24489623-ee58-4b4b-bbfa-c6422906eef5",
   "metadata": {},
   "source": [
    "we will start by the necessary importation and we will make sure to implement everything from scratch however it would be good to represent array as numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e93e69aa-315a-4e39-baf9-c6d8fcb74939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library numpy to represent vectors as numpy arrays\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cccc667-f0d0-4ebb-b8e7-ea5b13320caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model function \n",
    "def linear_regression_model (x , W ,b ):\n",
    "    # x is the vector of features \n",
    "    # W is the vector of parameters w \n",
    "    # b is a parameter represented as an integer \n",
    "    # the return is an integer f(x) \n",
    "    n = len(x) # n is the number of feature \n",
    "    f_X = 0.0 # the return value \n",
    "    for i in range (n) : \n",
    "        # looping over the feature \n",
    "        f_X += (x[i]*W[i]) \n",
    "    f_X += b \n",
    "    return f_X \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf22fb24-c513-4453-8fb1-3923a99d4cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.0\n"
     ]
    }
   ],
   "source": [
    "# here we will focus on testing the function \n",
    "# define x \n",
    "x = np.array([1,2,3])\n",
    "# define w \n",
    "w = np.array ([4,5,6])\n",
    "#define b \n",
    "b = 10 \n",
    "# we will check for the equality of the size \n",
    "xn = len (x) \n",
    "wn = len (w) \n",
    "if xn == wn : \n",
    "    print (linear_regression_model(x,w,b)) \n",
    "else : \n",
    "    print (\"the size of x and w has to be equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea650296-a54b-4097-9abc-46042ecf1609",
   "metadata": {},
   "source": [
    "### vectorization implementation \n",
    "now we will use a built function within the numpy to make the calculation faster , you might be wondering how it would make thing faster if you took a look at the loop in each iteration we are only in need of the current values and no previous values from a previous iteration thus using the numpy function it will run each iteration in parallel and then sum them this reduce the complexity from linear to constant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20800d93-6b51-4294-a55b-2b0ffa429d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model \n",
    "def linear_regression_model_with_vec (x , W , b )  : \n",
    "    # x is the vector of features (one example)\n",
    "    # W is the vector of parameters w \n",
    "    # b is a parameter represented as an integer \n",
    "    # the return is an integer f(x) \n",
    "    f_X = 0.0 # the returned value \n",
    "    f_X += np.dot(x, W)\n",
    "    f_X += b \n",
    "    return f_X \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e5e264b-e0f4-402f-a634-e6e6c726ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.0\n"
     ]
    }
   ],
   "source": [
    "# here we will focus on testing the function \n",
    "# define x \n",
    "x = np.array([1,2,3])\n",
    "# define w \n",
    "w = np.array ([4,5,6])\n",
    "#define b \n",
    "b = 10 \n",
    "# we will check for the equality of the size \n",
    "xn = len (x) \n",
    "wn = len (w) \n",
    "if xn == wn : \n",
    "    print (linear_regression_model_with_vec(x,w,b)) \n",
    "else : \n",
    "    print (\"the size of x and w has to be equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f01470-5989-4c90-943b-c7369c6f5cbc",
   "metadata": {},
   "source": [
    "## Cost \n",
    "instead of updating or trying different values of w and b manually until we reach to the one that gets the model to be accurate as much as possible it would be good if we were able to automate this operation using an optimazation function known as gradient descent to give it an insight of how well the model is doing we need to start by implementing a cost function that tells the optimization function how well it is doing. \n",
    "we will have a training set of m examples, each example consists of x(feature) and y(output). we will compute the regression model value of x f_x and compare it to the value given in the training y. then we will take the square of the difference to ensure that the value is positive sum it over all the examples and then to get the average divide by m. In machine learning it is very common to divide by 2 in addition to ensure that the numbers are quite good.  \n",
    "$ J(W,B) =  (sum_{i=1}^{m} i = \\ (f(x)^i-y^i)^2)/2m $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5df85b3-8c1e-4cee-8d3f-22beb4262764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cost function \n",
    "def squared_error_cost_fuction (X,Y,W,b ): \n",
    "    # X is the set of features in the training set \n",
    "    # Y is the set of outputs in the training set \n",
    "    # W is a vector of parameters \n",
    "    # b is a parameter \n",
    "    m = len(X) # the number of training example \n",
    "    diff = 0.0\n",
    "    for i in range (m) : \n",
    "        f_X=linear_regression_model_with_vec(X[i],W ,b) # compute the value using the model \n",
    "        diff += (f_X - Y[i])**2 # compute the error for one training example \n",
    "    diff /= (2*m ) # compute the average \n",
    "    return diff \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "103e9d53-d09d-4b58-9358-a2084dbe9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cost is 92.83333333333333\n"
     ]
    }
   ],
   "source": [
    "# define X\n",
    "X = np.array([[1.0, 2.0],\n",
    "              [3.0, 4.0],\n",
    "              [5.0, 6.0]])\n",
    "\n",
    "# define Y \n",
    "Y = np.array([7.0, 8.0, 9.0])\n",
    "# define W \n",
    "W = np.array ([1,2])\n",
    "# define b \n",
    "b = 10 \n",
    "# print the cost \n",
    "print (f'the cost is {squared_error_cost_fuction(X,Y,W,b) }')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
